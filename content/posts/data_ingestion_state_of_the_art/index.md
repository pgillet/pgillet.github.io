---
title: "Ingestion de donn√©es: √âtat de l'Art"
date: 2018-11-15T04:00:00+01:00

tags: ["Big Data", "Data Ingestion", "Hadoop", "Kylo", "Data Lake", "üá´üá∑"]
author: "Pascal Gillet"
picto_bubble: "fas fa-database"
---

L‚Äôingestion de donn√©es consiste √† extraire, transformer et charger de grands volumes de donn√©es √† partir de diverses sources, telles que des bases de donn√©es, des API, des serveurs FTP / SFTP, des fichiers, etc., dans un lac de donn√©es (_Data Lake_ en anglais).

"Data Lake" est un terme apparu au cours de cette d√©cennie pour d√©crire un √©l√©ment important du pipeline d'analyse de donn√©es dans le monde du Big Data. 

<!--more-->

L'id√©e est de disposer d'une zone de stockage unique pour toutes les donn√©es brutes que n'importe qui dans une organisation pourrait avoir besoin d'analyser. Habituellement, les gens utilisent Hadoop pour travailler sur les donn√©es du lac, mais le concept est plus large que Hadoop.

Pour rappel, il existe une distinction essentielle entre le lac de donn√©es et l‚Äô[entrep√¥t de donn√©es](https://fr.wikipedia.org/wiki/Entrep%C3%B4t_de_donn%C3%A9es) (et le [data mart](https://fr.wikipedia.org/wiki/Datamart)). Le lac de donn√©es stocke les donn√©es brutes, quelle que soit la forme fournie par la source de donn√©es :

- **Donn√©es structur√©es** issues de bases de donn√©es relationnelles (lignes, colonnes)
- **Donn√©es semi-structur√©es** : fichiers de logs, CSV, JSON, XML, etc.
- **Donn√©es non structur√©es** : emails, documents, PDFs mais aussi potentiellement des donn√©es binaires (images, audio, vid√©o)

Il n'y a pas d'hypoth√®ses sur le sch√©ma des donn√©es, chaque source de donn√©es peut utiliser le sch√©ma de son choix. Il incombe aux utilisateurs des donn√©es du lac de leur donner un sens pour leurs propres besoins.

Le lac de donn√©es est g√©n√©ralement d√©fini comme un r√©servoir de donn√©es pour des op√©rations de type ETL (Extract-Transform-Load), ou comme un hub central pour l‚Äôanalyse de donn√©es en libre-service. Le lac de donn√©es se r√©f√®re √©galement aux outils de gestion de la donn√©e au sein de la plate-forme (stockage, monitoring, etc.)

# Les outils
Les outils classiques/historiques de la data ingestion (en tout cas, ceux que j'ai eu l'occasion de manipuler √† maintes reprises) sont les suivants :

- **Apache Oozie**. Oozie est un ordonnanceur de workflows permettant de g√©rer des t√¢ches Hadoop. Les workflows Oozie sont des graphes acycliques dirig√©s (DAG) compos√©s d‚Äôactions. Les coordinators Oozie permettent de d√©clencher des workflows de fa√ßon r√©currente, √† une date et une heure sp√©cifi√©es √† l‚Äôavance (expression cron) et/ou √† la disponibilit√©e de la donn√©e (ex : un fichier d√©pos√© dans un espace r√©seau dont le nom correspond √† une expression r√©guli√®re).
Oozie est int√©gr√© √† l‚Äô√©cosyst√®me Hadoop et prend en charge plusieurs types de t√¢ches Hadoop pr√™tes √† l'emploi (telles que map-reduce Java, Spark, Pig, Hive, Sqoop et DistCp) ainsi que des t√¢ches sp√©cifiques au syst√®me (telles que des programmes Java et des scripts shell).  
- **Apache Hive** est un entrep√¥t de donn√©es distribu√© int√©gr√© √† Hadoop HDFS. Il fournit un langage de requ√™tes similaire √† SQL, et convertit de mani√®re transparente les requ√™tes en map-reduce Java, [Tez](https://tez.apache.org/) ou Spark. Hive est la solution principale de stockage des donn√©es source dans un cluster Hadoop.
- **Apache Sqoop** est un outil en ligne de commande pour transf√©rer des donn√©es en masse depuis des bases de donn√©es relationnelles vers Hive. Il prend en charge le chargement diff√©rentiel d‚Äôune table ou d‚Äôune requ√™te SQL depuis la derni√®re importation.
- **Apache Spark**. Spark est un framework de traitement distribu√© permettant d‚Äôex√©cuter des t√¢ches map-reduce en m√©moire. Spark SQL, notamment, permet d'ex√©cuter des requ√™tes en langage SQL pour charger et transformer des donn√©es.

![Data Lake failure](data-lake-failure-2-1600x640.jpg)

Beaucoup d'√©tudes ont √©t√© r√©alis√©es sur le bien-fond√© des lacs de donn√©es et sur les raisons pour lesquelles certaines initiatives de data lake ont √©chou√© dans de grandes entreprises.
Parmi ces raisons, on trouve que le probl√®me r√©side dans les outils et les m√©thodes utilis√©s pour alimenter le lac de donn√©es. L'ingestion de donn√©es d√©pend encore trop souvent d'un d√©veloppement personnalis√© pour chaque syst√®me source. Des outils sp√©cialement con√ßus et des scripts sp√©cifiques rendent l'ingestion de donn√©es volumineuses complexe, longue et co√ªteuse. Le syst√®me n'est pas scalable du fait de la trop grande vari√©t√© des sources, et de leurs volumes grandissants... Souvenez-vous, les [4 Vs du Big Data](https://www.ibmbigdatahub.com/infographic/four-vs-big-data) et les enjeux associ√©s.
Aussi, l'ingestion de donn√©es est souvent exclusivement r√©alis√©e par une √©quipe technique. Notamment, les interfaces en ligne de commande des outils de traitement des donn√©es existants cr√©ent des d√©pendances pour les d√©veloppeurs et entravent l'acc√®s aux donn√©es et √† la prise de d√©cision.

# La r√©volution industrielle du Big data

Pourtant, la (quatri√®me) r√©volution industrielle promise par le Big Data est bel et bien arriv√©e... depuis quelques ann√©es d√©j√†. Les volumes de donn√©es et la cadence √† laquelle les donn√©es sont ing√©r√©es augmentent sans cesse. Plus que jamais on parle de temps r√©el, de donn√©es en mouvement. Le Big Data s'ouvre √©galement √† de nouveaux types de donn√©es : donn√©es capteurs avec l'IoT, s√©ries temporelles continues, logs, etc.
Avant, on d√©posait les donn√©es directement dans Hadoop, √† la main, en mode _batch_. Maintenant, on parle d'[architecture Lambda](https://en.wikipedia.org/wiki/Lambda_architecture), capable de traitements par lots et en flux (√† ne pas confondre avec les Lambdas d'AWS et le serverless ou les expressions lambda de Java).
Les grandes distributions Hadoop se dotent ainsi de leur propre solution d'ingestion de donn√©es. Hortonworks Data Flow (HDF), par exemple, compl√®te Hortonworks Data Platform (HDP) en regroupant Apache NiFi, Kafka et Storm.
Il existe de plus en plus d'outils en p√©riph√©rie d'Hadoop d√©di√©s √† la collecte et au traitement des donn√©es. Pour preuve, le nombre grandissant de frameworks pour le traitement en streaming.

# Les frameworks orient√©s data
Il existe beaucoup d'outils et de frameworks orient√©s _data_ (data-driven).
\*Disclaimer\* : on ne parlera ici que des frameworks _open source_ de la fondation Apache.

De m√™me qu'on parle de "persistance polyglotte" ou de "programmation polyglotte", l'id√©e ici est que l'ingestion de donn√©es devrait √™tre op√©r√©e par un m√©lange de frameworks, afin de tirer parti du fait que diff√©rents frameworks sont adapt√©s √† la r√©solution de probl√®mes diff√©rents. Des flux d'ingestion complexes combinent diff√©rents types de probl√®mes, et choisir le bon framework pour une t√¢che sp√©cifique est plus productif que d'essayer de regrouper tous les aspects dans un seul framework.
Ainsi, la combinaison d‚Äôoutils pour r√©aliser des t√¢ches diff√©rentes de mani√®re plus efficace permet une accumulation de fonctionnalit√©s et une flexibilit√© accrue dans la gestion d‚Äôun ensemble plus vaste de sc√©narios : on parle alors d'architecture dite modulaire, plug-in ou encore de mashup.
Les outils et frameworks pouvant constituer une telle architecture et/ou compl√©ter les outils actuels sont les suivants :

- **Courtage de donn√©es** : Kafka, Storm. Kafka est le standard de-facto pour le transport de flux de donn√©es √† large √©chelle et permet notamment de r√©pondre au probl√®me de la _back pressure_ : les donn√©es sont produites plus vite qu‚Äôelles ne peuvent √™tre ing√©r√©es dans le lac de donn√©es.
- **Agents l√©gers** con√ßus pour le transfert de donn√©es : MiNiFi, Elastic Beats. Les agents sont install√©s sur les serveurs, au plus pr√®s des sources; ils collectent les donn√©es et les transf√®rent vers le lac de donn√©es.
- **Orchestration/planification de workflows** : NiFi, Oozie
- **Traitement batch et/ou streaming** : Sqoop, Spark (Streaming), Flume, Beam, Flink, Apex, Samza...
- **Data wrangling** : Parce que les donn√©es dans le lac ne sont pas si brutes que √ßa, et qu'il faut parfois nettoyer, standardiser, filtrer les donn√©es en fonction de restrictions locales ou anonymiser les sources. OpenNLP, pour le traitement du langage naturel, est parfois utilis√© dans ce contexte.

Hive peut √©galement √™tre compl√©t√© par d‚Äôautres solutions de stockage pour d‚Äôautres besoins et selon d‚Äôautres paradigmes : Elasticsearch ou Solr pour indexer et rechercher des donn√©es, buckets S3, bases de donn√©es orient√©es colonnes Cassandra ou Hbase, etc.

Vous trouverez un comparatif complet des frameworks de traitement de flux [ici](https://www.digitalocean.com/community/tutorials/hadoop-storm-samza-spark-and-flink-big-data-frameworks-compared) et [l√†](https://medium.com/@chandanbaranwal/spark-streaming-vs-flink-vs-storm-vs-kafka-streams-vs-samza-choose-your-stream-processing-91ea3f04675b).

Dans le reste de cet article, nous allons voir qu'il existe des outils avanc√©s permettant √† des utilisateurs finaux d'op√©rer l'ingestion de donn√©es, tout en dissimulant les d√©tails techniques qu'elle implique.

# Des outils tourn√©s vers l'utilisateur final

## Gobblin
[Apache Gobblin](https://gobblin.apache.org/) est un framework d√©velopp√© initialement par LinkedIn (vous vous souvenez de Kafka!?) qui d√©veloppait jusqu‚Äôalors des solutions customis√©es pour l‚Äôingestion de donn√©es dans leur √©cosyst√®me Hadoop, ce qui posait d‚Äôimportants probl√®mes de qualit√© des donn√©es, de gestion des m√©tadonn√©es, de d√©veloppement et d‚Äôexploitation. Cette exp√©rience a permis √† LinkedIn de th√©oriser et de mod√©liser de mani√®re tr√®s fine l‚Äôingestion de donn√©es. Le code source de Gobblin a depuis √©t√© ouvert et offert √† la fondation Apache. Le framework est cependant encore en incubation chez Apache, et si une interface Web fait partie de la feuille de route, elle n‚Äôest pas encore disponible. Le projet est tr√®s actif sur Github.

## Kylo
[Kylo](https://kylo.io/), avec Apache Gobblin, fait partie de ces nouveaux outils permettant √† des utilisateurs finaux d'op√©rer un cluster Hadoop et de cr√©er des flux d'ingestion complexes.

Kylo est une solution open source par Teradata pour la "cr√©ation acc√©l√©r√©e et la gestion de pipelines de donn√©es". Teradata propose √©galement du support sur sa solution. La plate-forme est propos√©e sous licence Apache 2.0 et est √©labor√©e sur la base de Hadoop, Spark et Apache NiFi. Teradata joue un r√¥le de leader en mati√®re de gouvernance, d'intendance et de d√©veloppement communautaire autour du projet open source Kylo.
Kylo fournit une interface utilisateur en libre-service et est certainement l‚Äôoutil de gestion de lacs de donn√©es le plus avanc√© parmi tous les outils (open source) √©tudi√©s dans le cadre de cet article.

En termes de d√©ploiement et d'architecture :

- Kylo est une application Web install√©e sur un noeud _edge_ Linux d'un cluster Spark & Hadoop.
- Kylo contient un certain nombre de routines sp√©cialement con√ßues pour les op√©rations de Data Lake en utilisant Hive et Spark (_profiling_, validation et nettoyage des donn√©es, d√©tection de sch√©ma, etc.).
- **Kylo utilise Apache NiFi en tant que _scheduler_ (planification, ordonnancement de t√¢ches) et moteur d'orchestration**, fournissant un framework int√©gr√© pour la conception de pipelines de donn√©es avec 200 "processeurs" pr√©d√©finis (connecteurs √† des sources de donn√©es, transformations). Nifi est fond√© sur le [flow-based programming](https://en.wikipedia.org/wiki/Flow-based_programming).
- Kylo peut s'int√©grer √† Apache Ranger ou Sentry et √† CDH Navigator (Cloudera) ou Ambari (Hortonworks) pour le _monitoring_ du cluster.
- Kylo peut √™tre d√©ploy√© dans le cloud.
- Kylo est Hautement Disponible (HA) si d√©ploy√© en cluster accessible via un _Load Balancer_.  

> Kylo emploie des mod√®les d‚Äôingestion r√©utilisables (templates Nifi).

**Apache NiFi constitue la base essentielle de Kylo.**
Les administrateurs de Kylo d√©terminent comment les utilisateurs peuvent configurer des flux en fonction de mod√®les de traitement. L‚Äôadministrateur (ou plut√¥t ici le concepteur) est ainsi responsable du d√©veloppement de ces mod√®les dans Apache NiFi. Une fois qu'un mod√®le a √©t√© enregistr√© dans Kylo via une interface d'administration, Kylo permet aux utilisateurs finaux de cr√©er et de configurer des flux via un assistant (_wizard_) cr√©√© dynamiquement sur la base de ce mod√®le. L'utilisation de mod√®les rend donc Kylo hautement configurable.

![Kylo source definition](kylo-define-source.png)

![Kylo feed definition" caption="Les utilisateurs peuvent facilement configurer des flux dans une interface utilisateur guid√©e](kylo-define-feed.png)

Le concepteur d√©termine les param√®tres pouvant √™tre saisis par un utilisateur final dans l'interface de l'assistant, et comment ces champs sont affich√©s (par exemple : liste de s√©lection, fen√™tre SQL, champ num√©rique, etc.), ainsi que les valeurs par d√©faut ou les contraintes. Les param√®tres saisis servent √† configurer les outils sous-jacents n√©cessaires au traitement du flux, en prenant en compte la s√©curit√©, les exigences de la Data Governance et la gestion des erreurs. Les utilisateurs peuvent uniquement d√©finir les param√®tres expos√©s par le concepteur de mod√®les.
Les √©l√©ments du mod√®le qui r√©alisent le traitement du flux sont les processeurs NiFi. Il existe plusieurs types de processeurs, pour obtenir des fichiers, lire depuis Twitter ou Kafka, ex√©cuter des requ√™tes SQL sur une base de donn√©es, compresser ou d√©compresser des fichiers, envoyer des donn√©es via SFTP ou supprimer un fichier dans Hadoop. Apache NiFi fournit toute une biblioth√®que de processeurs standards. Apache Nifi est extensible : il est possible de d√©velopper ses propres processeurs. Ceci permet un d√©veloppement rapide et des tests efficaces de nouveaux sc√©narios d‚Äôingestion de donn√©es.

![Nifi template" caption="Le template Nifi permettant de g√©n√©rer l'assistant Kylo vu plus haut](nifi.png)

Kylo fournit une architecture de type plug-in avec une vari√©t√© d'extensions √† la disposition des d√©veloppeurs, et l'utilisation de mod√®les NiFi offre une grande  flexibilit√© pour impl√©menter et exp√©rimenter divers sc√©narios d‚Äôingestion de donn√©es sp√©cifiques √† une entreprise, pour les cas d'utilisation par lots et en flux.

Vous trouverez une liste compl√®te des fonctionnalit√©s de Kylo [ici](https://kylo.readthedocs.io/en/v0.9.1/about/KyloFeatures.html).

# Et demain?

## Mettre en cache plut√¥t que copier les donn√©es?
L'ingestion de donn√©es, on l'a vu, consiste √† collecter les donn√©es de diff√©rentes sources et √† les dupliquer dans le Data Lake. Copier les donn√©es pour ne pas solliciter trop souvent les sources : en effet, les sources n'ont pas pour objectif de servir les donn√©es en dehors du contexte d'utilisation pour lequel elles ont √©t√© mises en place au d√©part (c'est-√†-dire le seul projet ou syst√®me d'information ayant besoin de persister puis d'interroger ses donn√©es).
Copier les donn√©es aussi parce que la source de donn√©es n'est pas (facilement) accessible ou interrogeable, en dehors de ce contexte et du mode op√©ratoire mis en place pour r√©aliser cette copie justement.

J'ai toujours pens√© que c'√©tait une faute de r√©pliquer ainsi les donn√©es, sans compter que cela pose le probl√®me majeur de la synchronisation des donn√©es du Data Lake avec les sources (mise √† jour compl√®te, incr√©mentale ou diff√©rentielle).
En effet, ne pourrait-on pas laisser les donn√©es l√† o√π elles r√©sident? On pourrait ainsi les requ√™ter seulement quand on en a besoin, et on serait assur√© qu'elles sont bien √† jour.

> On retrouve le concept cher √† [Tim Berners-Lee](https://fr.wikipedia.org/wiki/Tim_Berners-Lee) du Web des donn√©es (_Linked Data_, en anglais). Le Web des donn√©es s'appuie sur les standards du Web (HTTP et URI), et permet d'interroger automatiquement les donn√©es, quels que soient leurs lieux de stockage, et sans avoir √† les dupliquer.

Il faudrait pour cela augmenter la capacit√© des sources √† pr√©senter leurs donn√©es, en leur ajoutant un syst√®me de cache par exemple. En effet, la mise en cache peut am√©liorer la disponibilit√© des donn√©es en fournissant un service continu √† des applications tierces - d'analyse de donn√©es en l'occurence - qui d√©pendent uniquement des donn√©es en cache, m√™me si la source principale n'est pas disponible.
La mise en cache dans un environnement en cluster peut encore augmenter la disponibilit√© des donn√©es et assure l'√©quilibrage de la charge des requ√™tes.

Bon nombre de produits proposent une couche interm√©diaire d'acc√®s aux donn√©es entre le stockage (fichiers, SGBDRs, stockage objet, etc.) et les applications de traitement :

- [Couchbase](https://www.couchbase.com/fr) ou [Redis](https://redis.io/) supportent divers sc√©narios de mise en cache distribu√©e
- [Apache Ignite](https://ignite.apache.org/) propose une plate-forme de mise en cache
- [Alluxio](https://www.alluxio.org/), anciennement Tachyon, certainement la plate-forme de mise en cache la plus populaire √† ce jour
- [Hazelcast](https://en.wikipedia.org/wiki/Hazelcast), [Infinispan](http://infinispan.org/), etc., d'autres plates-formes distribu√©es
- CSQL Cache, TimesTen, SafePeak, Tarantool, Heimdall Data proposent des caches pour des bases de donn√©es SQL
- [memcached](https://memcached.org/)

Ces services de mise en cache partag√©s et distribu√©s apportent un v√©ritable gain de performance en pla√ßant en m√©moire de mani√®re transparente les donn√©es fr√©quemment utilis√©es. Ils g√®rent √©galement la communication entre les applications et le stockage en traduisant automatiquement les demandes d'acc√®s aux donn√©es des applications vers toute interface de stockage persistant sous-jacente.

Finalement, quand on y r√©fl√©chit, un Data Lake peut √™tre vu comme un cache g√©ant regroupant toutes les donn√©es d'une entreprise.
Si le Data Lake d'aujourd'hui utilise plut√¥t des solutions de stockage durable (sur disque), le Data Lake du futur fera la part belle aux solutions de stockage en m√©moire.

## D√©silotage des donn√©es
> L'enjeu principal du Data Lake est de *d√©siloter* les donn√©es.

La majorit√© des entreprises gardent leurs donn√©es dans des sources de donn√©es qui ne communiquent pas entre elles : les silos.
Il n'est pas rare de rencontrer de tels silos dans les grandes entreprises, o√π chaque canal d√©pend de son propre service et o√π les services ont leurs propres objectifs, budgets, etc.
Le Data Lake doit donc favoriser la publication de donn√©es, non pas sous la forme de silos de donn√©es isol√©s les uns des autres, mais en les reliant entre elles pour constituer un r√©seau global d'informations.

Si le Data Lake n'est pas responsable du merge et de la r√©conciliation des donn√©es (c'est justement la t√¢che des projets d'analyse en aval), il doit en revanche fournir les moyens d'y parvenir, notamment un catalogue de donn√©es pour r√©pertorier les ensembles de donn√©es et permettre leur d√©couverte. Il doit √©galement fournir un index complet pour la recherche et la localisation des sources.
Enfin, le Data Lake peut fournir une fa√ßade aux utilisateurs finaux, et jouer le r√¥le de proxy pour interroger les donn√©es depuis les sources d‚Äôorigine, avec un g√©n√©rateur de requ√™tes SQL par exemple.

## Lambda est mort, Vive Lambda !

Dans une architecture Lambda moderne, typique des √©cosyst√®mes IoT, certaines des sources (des capteurs par exemple) n'ont pas de stockage, mais produisent plut√¥t des flux de donn√©es. Dans ce cas, vous aurez besoin d‚Äôun pipeline d‚Äôingestion, qui capture les donn√©es, les conserve dans un buffer, applique potentiellement certaines transformations et finit √©ventuellement par les d√©poser dans le lac. Kafka et Spark Streaming sont des outils communs dans ce domaine.

Dans ce cas, conserver (temporairement) les donn√©es dans le lac permet de les traiter et de les analyser _a posteriori_, si un traitement √† la vol√©e n‚Äôest pas possible (_streaming analytics_). Le Data Lake joue bien le r√¥le de cache de donn√©es.

En conclusion, les architectures de Big Data √©voluent et se multiplient sans cesse. On parle d'architecture Lambda, m√©langeant les traitements en batch et en temps r√©el; d'architecture [Kappa](https://www.oreilly.com/ideas/questioning-the-lambda-architecture), o√π tout est flux; SMACK pour Spark-Mesos-Akka-Cassandra-Kafka, l'√©quivalent de la stack LAMP pour le Big Data, etc.
Les usages √©voluent √©galement : on traite de plus en plus de logs applicatifs, de s√©ries temporelles, de donn√©es capteurs...
Peu importe les patterns d'architecture mis en oeuvre et les lettres grecques utilis√©es pour les d√©signer, une bonne architecture de Big Data est une architecture √©volutive, capable de composer avec diff√©rents outils et de s'adapter √† de nouveaux besoins, tout simplement.


---
Pour aller plus loin :

- [Gartner Says Beware of the Data Lake Fallacy](https://www.gartner.com/newsroom/id/2809117)
- [Gartner Reveals the 2017 Hype Cycle for Data Management](https://www.gartner.com/en/newsroom/press-releases/2017-09-28-gartner-reveals-the-2017-hype-cycle-for-data-management)
- [Why Data Lakes Are Evil](https://www.forbes.com/sites/danwoods/2016/08/26/why-data-lakes-are-evil/#5291a9e44f73)
- [The Future Architecture of a Data Lake : In-memory Data Exchange Platform Using Tachyon and Apache Spark](https://content.pivotal.io/blog/the-future-architecture-of-a-data-lake-in-memory-data-exchange-platform-using-tachyon-and-apache-spark)
